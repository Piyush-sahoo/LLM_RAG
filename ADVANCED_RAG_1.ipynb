{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.215132Z",
     "start_time": "2024-07-31T06:25:14.045334Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import time\n",
    "import pandas as pd\n",
    "from langchain import hub\n",
    "import google.generativeai as genai\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.text_splitter import  RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "import json\n",
    "# AIzaSyCgBe8_4ZTv-gSGyaKitDq5byINM8NKVtc\n",
    "# ZenGuardAI : \"jLsY36WTItelQFc-r6BemvWkVLIkoWJQVLdbyrE-7aQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1317d042cce29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.246028Z",
     "start_time": "2024-07-31T06:25:20.220030Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_API_KEY'] = 'AIzaSyBRuhK8YWtQVGI6Lj-ROslrDoytHDcCNqY'\n",
    "# os.environ['GOOGLE_API_KEY'] = \"AIzaSyCgBe8_4ZTv-gSGyaKitDq5byINM8NKVtc\"\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyCgBe8_4ZTv-gSGyaKitDq5byINM8NKVtc\"\n",
    "\n",
    "# os.environ['GOOGLE_API_KEY'] = \"AIzaSyDoa4gmpnbR48ASLFWnxzyld9g2m8gGAtw\"\n",
    "# os.environ['GOOGLE_API_KEY'] = \"AIzaSyDoa4gmpnbR48ASLFWnxzyld9g2m8gGAtw\"\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff32c4a764093c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.294146Z",
     "start_time": "2024-07-31T06:25:20.248029Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0.3)\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8ad45e04637fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.309275Z",
     "start_time": "2024-07-31T06:25:20.296029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure the Generative AI API\n",
    "genai.configure(api_key=\"AIzaSyCgBe8_4ZTv-gSGyaKitDq5byINM8NKVtc\")\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732735c00a15adc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.324277Z",
     "start_time": "2024-07-31T06:25:20.312232Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_pdf(file_path):\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            document = fitz.open(file_path)\n",
    "            all_text = \"\"\n",
    "            for page_num in range(document.page_count):\n",
    "                page = document.load_page(page_num)\n",
    "                all_text += page.get_text()\n",
    "            document.close()  \n",
    "            return all_text\n",
    "        else:\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from file {file_path}: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631288fabb72008a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.339789Z",
     "start_time": "2024-07-31T06:25:20.326173Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_pdf_as_images(pdf_path, output_folder):\n",
    "    try:\n",
    "        document = fitz.open(pdf_path)\n",
    "        base_filename = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        len_document = len(document)\n",
    "        \n",
    "        # Calculate indices to skip\n",
    "        start_skip = len_document // 3  # Skip the first third\n",
    "        end_skip = len_document - 1     # Skip the last page\n",
    "        \n",
    "        image_paths = []\n",
    "        for page_num in range(start_skip, end_skip):\n",
    "            page = document.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            image_filename = f\"{base_filename}_page_{page_num + 1}.png\"\n",
    "            image_path = os.path.join(output_folder, image_filename)\n",
    "            pix.save(image_path)\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"Saved {image_path}\")\n",
    "\n",
    "        document.close()  # Close the document after processing\n",
    "        return image_paths\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting PDF to images: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64285a3d2dd916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.355736Z",
     "start_time": "2024-07-31T06:25:20.342803Z"
    }
   },
   "outputs": [],
   "source": [
    "# def process_folder(folder_path, output_image_folder):\n",
    "#     if not os.path.exists(output_image_folder):\n",
    "#         os.makedirs(output_image_folder)\n",
    "# \n",
    "#     results = []\n",
    "# \n",
    "#     for filename in os.listdir(folder_path):\n",
    "#         if filename.endswith(\".pdf\"):\n",
    "#             file_path = os.path.join(folder_path, filename)\n",
    "#             print(f\"Processing file: {file_path}\")\n",
    "# \n",
    "#             # Extract text from PDF\n",
    "#             paper_text = extract_text_pdf(file_path)\n",
    "# \n",
    "#             # Convert PDF pages to images and get image paths\n",
    "#             image_paths = save_pdf_as_images(file_path, output_image_folder)\n",
    "# \n",
    "#             # Process each image with the Generative AI model\n",
    "#             image_descriptions = []\n",
    "#             for image_path in image_paths:\n",
    "#                 try:\n",
    "#                     sample_file = genai.upload_file(path=image_path, display_name=os.path.basename(image_path))\n",
    "#                     print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n",
    "#                     \n",
    "#                     # Prompt the model with text and the previously uploaded image\n",
    "#                     response = model.generate_content([sample_file, \"Concentrate on the Graphical Representation, take into consideration the textual context, and get the insights about the graphs ?\"])\n",
    "#                     image_descriptions.append(response.text)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "#                     image_descriptions.append(\"Error processing image\")\n",
    "# \n",
    "#             # Combine all image descriptions\n",
    "#             image_description_text = \"\\n\".join(image_descriptions)\n",
    "# \n",
    "#             # Add results to the list\n",
    "#             results.append([paper_text, image_description_text])\n",
    "# \n",
    "#     # Create a DataFrame from the results\n",
    "#     result_df = pd.DataFrame(results, columns=[\"PDF Text\", \"Image Descriptions\"])\n",
    "#     return result_df\n",
    "\n",
    "def process_folder(folder_path, output_image_folder):\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "\n",
    "            # Extract text from PDF\n",
    "            paper_text = extract_text_pdf(file_path)\n",
    "\n",
    "            # Convert PDF pages to images and get image paths\n",
    "            image_paths = save_pdf_as_images(file_path, output_image_folder)\n",
    "            # Process each image with the Generative AI model\n",
    "            image_descriptions = []\n",
    "            for image_path in image_paths:\n",
    "                try:\n",
    "                    # Upload the image\n",
    "                    sample_file = genai.upload_file(path=image_path, display_name=os.path.basename(image_path))\n",
    "                    print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n",
    "                    \n",
    "                    # Prompt the model with text and the previously uploaded image\n",
    "                    response = model.generate_content([sample_file, \"Concentrate on the Graphical Representation, take into consideration the textual context, and get the insights about the graphs ?\"])\n",
    "                    image_descriptions.append(response.text)\n",
    "                    \n",
    "                    # Add a delay of 20 seconds\n",
    "                    time.sleep(40)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "                    image_descriptions.append(\"Error processing image\")\n",
    "\n",
    "            # Combine all image descriptions\n",
    "            image_description_text = \"\\n\".join(image_descriptions)\n",
    "\n",
    "            # Add results to the list\n",
    "            results.append([paper_text, image_description_text])\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    result_df = pd.DataFrame(results, columns=[\"PDF Text\", \"Image Descriptions\"])\n",
    "    return result_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1035a8c3ad212fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:25:20.371746Z",
     "start_time": "2024-07-31T06:25:20.357646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the path to your folder containing PDF files and the folder to save images\n",
    "folder_path = r'C:\\Desktop\\hello'\n",
    "output_image_folder = 'Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a0ef3abad3af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:08.279610Z",
     "start_time": "2024-07-31T06:25:20.373644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process the folder and create the DataFrame\n",
    "result_df_1 = process_folder(folder_path, output_image_folder)\n",
    "print(result_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e02ba0549cc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:15.043446Z",
     "start_time": "2024-07-31T06:39:15.031073Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf_text = result_df_1.columns[0]\n",
    "Image_Descriptions = result_df_1.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0318942a4bf6a94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:16.019977Z",
     "start_time": "2024-07-31T06:39:15.992974Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df_1.to_csv(\"hello.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3a1ee06345918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:16.636975Z",
     "start_time": "2024-07-31T06:39:16.600975Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_image_descriptions_text = DataFrameLoader(result_df_1, page_content_column=Image_Descriptions)\n",
    "df_image_descriptions = loader_image_descriptions_text.load()\n",
    "df_image_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65226502ed1ec140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:17.127053Z",
     "start_time": "2024-07-31T06:39:17.110053Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_documents = DataFrameLoader(result_df_1, page_content_column=pdf_text)\n",
    "documents = loader_documents.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0e5e87a80ff64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:17.651024Z",
     "start_time": "2024-07-31T06:39:17.628022Z"
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200)\n",
    "splits_1 = text_splitter.split_documents(documents=documents)\n",
    "splits_2 = text_splitter.split_documents(documents=df_image_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d5b4ba68897e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:30.034418Z",
     "start_time": "2024-07-31T06:39:18.048464Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits_1, embedding=embeddings_model)\n",
    "vectorstore_1 = Chroma.from_documents(documents=splits_2, embedding=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680a289180f62c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.353378Z",
     "start_time": "2024-07-31T06:39:30.037546Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b860970b6bd376d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.367377Z",
     "start_time": "2024-07-31T06:39:32.356376Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever_1 = vectorstore.as_retriever()\n",
    "retriever_2 = vectorstore_1.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b34fb4decaeace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.383374Z",
     "start_time": "2024-07-31T06:39:32.370376Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee2ff93806e83a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.399378Z",
     "start_time": "2024-07-31T06:39:32.385382Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5e0b83a69ca77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.415408Z",
     "start_time": "2024-07-31T06:39:32.401374Z"
    }
   },
   "outputs": [],
   "source": [
    "count_files = len(os.listdir(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc76c94456202c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.431376Z",
     "start_time": "2024-07-31T06:39:32.418385Z"
    }
   },
   "outputs": [],
   "source": [
    "# def title_extract(count_files_1, result_df):\n",
    "#     title_partial = ''\n",
    "#     for i in range(count_files_1):\n",
    "#         title_partial += result_df['Paper_text'][i][:360]\n",
    "#     return title_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388fee19aa1804f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.447374Z",
     "start_time": "2024-07-31T06:39:32.434380Z"
    }
   },
   "outputs": [],
   "source": [
    "# title_extract_final = title_extract(count_files, result_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e35be4c73cba36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:32.463375Z",
     "start_time": "2024-07-31T06:39:32.448377Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0659901a7ffb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:33.678874Z",
     "start_time": "2024-07-31T06:39:32.468375Z"
    }
   },
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an expert researcher, analyse the context given and answer the questions.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt_5 = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aa5428e81f06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:33.741461Z",
     "start_time": "2024-07-31T06:39:33.681872Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.semanticscholar.tool import SemanticScholarQueryRun\n",
    "tools_1 = [SemanticScholarQueryRun()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d77ad9237c25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:33.757458Z",
     "start_time": "2024-07-31T06:39:33.744457Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm=llm, tools=tools_1, prompt=prompt_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96929fee27fb1b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:33.773464Z",
     "start_time": "2024-07-31T06:39:33.759455Z"
    }
   },
   "outputs": [],
   "source": [
    "agent_executor_1 = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools_1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b234ef0152f7c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:39:33.789485Z",
     "start_time": "2024-07-31T06:39:33.777460Z"
    }
   },
   "outputs": [],
   "source": [
    "# question = \"what are the research topics and research questions based on topics which can be worked upon based on the research papers given?\"\n",
    "# question = \"What are the datasets that were used in the given research papers about ?\"\n",
    "# question = \"Discuss the performance of the models that were employed in the research papers given, And Do a comparitive Analysis among the different models employed, And just mention the perfomance metrics, wrt to each model, No need of comments to justify the difference ?\"\n",
    "question = \"Mention the techniques used in the given papers given, and their performance analysis of techniques used ?\"\n",
    "question_1 = \"Can you Get me the best technique which had the best results, that were used in Topics Similar to Lung Cancer risk assessment and and it's effect on the heart.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0bec45f6aa11f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:42:44.791099Z",
     "start_time": "2024-07-31T06:42:44.791099Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from zenguard import Credentials, Detector, ZenGuard, ZenGuardConfig\n",
    "# os.environ[\"ZEN_API_KEY\"] = \"jLsY36WTItelQFc-r6BemvWkVLIkoWJQVLdbyrE-7aQ\"\n",
    "# api_key_ZEN = os.environ.get(\"ZEN_API_KEY\")\n",
    "# config = ZenGuardConfig(credentials=Credentials(api_key=api_key_ZEN))\n",
    "# zenguard = ZenGuard(config=config)\n",
    "# \n",
    "# response = zenguard.detect(detectors=[Detector.BANNED_TOPICS, Detector.PROMPT_INJECTION,  Detector.TOXICITY], prompt=question)\n",
    "# if response.get(\"is_detected\"):\n",
    "#     print(\"Banned topics detected. We should not talk about it. | Toxicity Detected\")\n",
    "# else:\n",
    "#     print(\"No banned topics detected. Carry on.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39db7f35bc653db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:42:53.084147Z",
     "start_time": "2024-07-31T06:42:53.072168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a1dfedd974f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:42:53.441707Z",
     "start_time": "2024-07-31T06:42:53.430705Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    |(lambda x: x.split(\"\\n\")) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7da2c77082a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:42:55.643436Z",
     "start_time": "2024-07-31T06:42:53.779565Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_queries.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2baa9d3a64094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:47:32.500453Z",
     "start_time": "2024-07-31T06:42:55.647437Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = question\n",
    "retrieval_chain = generate_queries | retriever_1.map() | generate_queries | retriever_2.map()| get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa640c755bc1ed6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:47:32.529499Z",
     "start_time": "2024-07-31T06:47:32.505450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages  \n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt_1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer, Assuming that the Required Resources were provided. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e0c704128dc4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:47:33.465024Z",
     "start_time": "2024-07-31T06:47:32.533629Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_queries_step_back = prompt_1 | llm | StrOutputParser()\n",
    "question = question\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e2dbe44fe8d2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:47:33.478977Z",
     "start_time": "2024-07-31T06:47:33.468509Z"
    }
   },
   "outputs": [],
   "source": [
    "text_hello = ''\n",
    "for i in df_image_descriptions:\n",
    "    text_hello+=str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2fb7727c62d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:47:33.509861Z",
     "start_time": "2024-07-31T06:47:33.486465Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "hello_dict = {}\n",
    "hello_dict['context'] = text_hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd2f509b7a7df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:47:33.541275Z",
     "start_time": "2024-07-31T06:47:33.513864Z"
    }
   },
   "outputs": [],
   "source": [
    "hello_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355edda1be9500e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:48:21.184345Z",
     "start_time": "2024-07-31T06:47:33.544171Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableLambda\n",
    "# Response prompt \n",
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "# {Image_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retrieval_chain ,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retrieval_chain ,\n",
    "        #Retrieve context from Image description\n",
    "        \"Image_context\": RunnableLambda(lambda x : Image_Descriptions),\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    }\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "text_chain = chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c1e818dca91c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T06:48:21.278814Z",
     "start_time": "2024-07-31T06:48:21.186249Z"
    }
   },
   "outputs": [],
   "source": [
    "text_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238b2ac9b936b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_replaced = text_chain.replace('*', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efed51c988163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_text_1 = text_replaced.split('\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac065ceef3571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(modified_text_1)):\n",
    "    if modified_text_1[i] == '':\n",
    "        modified_text_1.pop(i)\n",
    "    else:\n",
    "        modified_text_1[i] = modified_text_1[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9f7a14576c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d285325e86198",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
